{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 21st Century Piracy Phenomenon. Exploring Contemporary Sea Piracy\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this study the main goal is to evaluate the concentrations of the modern piracy incidents around the world.\n",
    "Modern-day pirates around the world share the legal designation of their historic brethren as “enemies of all mankind” because they disrupt and hinder the safe navigation of maritime vessels containing goods and people. \n",
    "\n",
    "Piracy is a global crime which impedes the free movement of ships containing people and goods, with its attendant economic ramifications. The perpetrators are usually heavily armed, with sophisticated weapons to enable them to hijack a vessel or vessels and redirect them to their desired location for the payment of an expected ransom.\n",
    "\n",
    "I am using Beautiful Soup for this Python app. Beautiful Soup is a Python library for parsing data out of HTML and XML files (aka webpages). It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. \n",
    "\n",
    "The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library. Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software.\n",
    "\n",
    "The data I used came from Live Piracy & Armed Robbery Report 2020. Reference: https://www.icc-ccs.org/index.php/piracy-reporting-centre/live-piracy-report\n",
    "\n",
    "![Home Page](images/home.png)\n",
    "\n",
    "## Main goal\n",
    "\n",
    "+ To access all of the content from the source code of the webpage with Python\n",
    "+ Parse and extract data. \n",
    "+ Save the info in CSV file for further analysis.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. Import Modules\n",
    "2. Get the URL link\n",
    "3. Navigate the URL Data Structure\n",
    "4. Testing out data requests\n",
    "5. Write data to a file in pseudo-code:\n",
    "    + Open up a file to write in and append data. \n",
    "    + Write headers\n",
    "    + Clear HTML tag and insert text in array\n",
    "    + Clear \\r \\n \\t to prepare string variable to clear Narrations: and insert text in array\n",
    "    + Prepare string variables Date, Time, Position, Area and Country, replace characters to insert character | and insert text in array\n",
    "    + Split to elements to array results for character | and Write to file items Date, Time, Position, Area and Country\n",
    "    + When complete, close the file\n",
    "6. The output file in CSV format.\n",
    "\n",
    "## Data info extracted:\n",
    "\n",
    "Date, Time, Position, Area and Country of Live Piracy & Armed Robbery Report 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![piracy reporting centre](images/piracy_reporting_centre.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have Beautiful Soup, install with 'conda install beautifulsoup' in terminal.\n",
    "\n",
    "Python requires us to explicitly load the libraries that we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have Beautiful Soup, install with 'conda install beautifulsoup' in terminal\n",
    "# Python requires us to explicitly load the libraries that we want to use:\n",
    "import requests\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a webpage into python so that we can parse it and manipulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a webpage into python so that we can parse it and manipulate it.\n",
    "URL = 'https://www.icc-ccs.org/index.php/piracy-reporting-centre/live-piracy-report'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control of Connection. We just turned the website code into a Python object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control of Connection\n",
    "# We just turned the website code into a Python object. \n",
    "response = requests.get(URL)\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the tags with class narrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the tags with class narrations\n",
    "data = soup.findAll(attrs={'class':['jos_fabrik_icc_ccs_piracymap2016___narrations']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Source Code HTML](images/code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open new file, make sure path to your data file is correct.\n",
    "\n",
    "Later, I write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('piracy_reporting_centre.csv','w') # open new file, make sure path to your data file is correct\n",
    "f.write(\"Date\\tTime\\tPosition\\tArea\\tCountry\" + \"\\n\") # write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear HTML tag and insert text in array\n",
    "results = []                              # Inicializa arreglo results\n",
    "for element in data:                      # Itera sobre el arreglo data\n",
    "     TAG_RE = re.compile(r'<[^>]+>')      # Prepara patron para limpiar tag html de las cadenas str(element)\n",
    "     text = TAG_RE.sub('', str(element))  # Aplica patron y limpia tag html de text\n",
    "     results.append(text)                 # Insert text in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear \\r \\n \\t to prepare string variable to clear Narrations: and insert text in array\n",
    "results_explode = []      # Inicializa arreglo results_explode\n",
    "results_2 = []            # Inicializa arreglo results_2\n",
    "for element in results:   # Itera sobre el arreglo results de la celda anterior\n",
    "     item = ''            # Inicializa item\n",
    "     item = str(element)  # Le asigna el valor de item a cada elemento del arreglo results\n",
    "     item = item.replace('\\r', '').replace('\\n', '').replace('\\t', '') # Reemplaza de item \\r, \\n, \\t para limpiar cadena y poder trabajar mejor en ella\n",
    "     if item != 'Narrations:':                 # Se utiliza para limpiar de la cadena la cadena Narrations:\n",
    "          results_explode = item.split(\".\")    # Realiza explode por el . para quedarnos con los elementos de la primera linea donde estan Date, Time, Position, Area and Country y eliminar el parrafo que tiene a continuacion la linea \n",
    "          i = 0                                # Inicializa i\n",
    "          for result in results_explode:       # Itera sobre el arreglo results_explode\n",
    "                i = i + 1\n",
    "                if i <= 5: results_2.append(result) # Guarda los elementos donde despues se pueden extraer Date, Time, Position, Area and Country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare string variables Date, Time, Position, Area and Country, replace characters to insert character | and insert text in array\n",
    "i = 0                      # i\n",
    "results = []               # Inicializa arreglo results\n",
    "for element in results_2:  # Itera sobre el arreglo results_2\n",
    "    i = i + 1\n",
    "    if i == 1: \n",
    "        data1 = str(element)  # toma elemento data1 para conformar la fecha\n",
    "    if i == 2: \n",
    "        data2 = str(data1) + '.' + str(element) # toma elemento data1 y concatena str(element) para conformar la fecha\n",
    "    if i == 3: \n",
    "        date = data2 + '.' + str(element) # toma elemento date mas otras cadenas y concatena str(element) para conformar la fecha\n",
    "    if i == 4: \n",
    "        position = str(element)    # toma elemento position mas otras cadenas\n",
    "    if i == 5: \n",
    "        country = str(element)     # toma elemento country mas otras cadenas\n",
    "        item = date.replace(': Posn : ', '|').replace(': Posn: ', '|').replace(': ', '|') + '.' + position.replace(' – ', '|') + '.' + country.replace('E, ', 'E|').replace('W, ', 'W|')\n",
    "        item = item.replace('N – ', 'N|').replace('W, ', 'W|') # Realiza reeplazo de : Posn : por |, : Posn: por |, : por |,  –  por |, E, por E|, W, por W| para conformar una linea donde estan bien delimitados los elemento Date, Time, Position, Area and Country por el separador |  \n",
    "        results.append(item)    # Adiciona la linea donde estan bien delimitados los elemento Date, Time, Position, Area and Country por el separador | al arreglo results\n",
    "        i = 0                   # Pone  en 0 para poder tomar los sgtes 5 elementos del arreglos results_2 donde estan los elementos utiles a extraer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to elements to array results for character | and Write to file items Date, Time, Position, Area and Country\n",
    "for element in results:\n",
    "       item = element.split(\"|\") # Realiza explode por el caracter | para quedarnos con los elementos Date, Time, Position, Area and Country\n",
    "       i = 0\n",
    "       for element1 in item:\n",
    "            i = i + 1\n",
    "            if i == 1: \n",
    "                date = str(element1)\n",
    "                f.write(date + \"\\t\") # fecha date and add tabulator\n",
    "            if i == 2: \n",
    "                time = str(element1)\n",
    "                f.write(time + \"\\t\") # fecha time and add tabulator\n",
    "            if i == 3: \n",
    "                position = str(element1)\n",
    "                f.write(position + \"\\t\") # fecha position and add tabulator\n",
    "            if i == 4: \n",
    "                area = str(element1)\n",
    "                f.write(area + \"\\t\") # fecha area and add tabulator\n",
    "            if i == 5: \n",
    "                country = str(element1)\n",
    "                f.write(country + \"\\t\\n\") # fecha country and add tabulator                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close file\n",
    "f.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cvs data](images/cvs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "We used Beautiful Soup as the main tool. The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library.\n",
    "\n",
    " Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
