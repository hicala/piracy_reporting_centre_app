{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 21st Century Piracy Phenomenon. Exploring Contemporary Sea Piracy\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this study the main goal is to evaluate the concentrations of the modern piracy incidents around the world.\n",
    "Modern-day pirates around the world share the legal designation of their historic brethren as “enemies of all mankind” because they disrupt and hinder the safe navigation of maritime vessels containing goods and people.\n",
    "\n",
    "Piracy is a global crime which impedes the free movement of ships containing people and goods, with its attendant economic ramifications. The perpetrators are usually heavily armed, with sophisticated weapons to enable them to hijack a vessel or vessels and redirect them to their desired location for the payment of an expected ransom.\n",
    "\n",
    "I am using Beautiful Soup for this Python app. Beautiful Soup is a Python library for parsing data out of HTML and XML files (aka webpages). It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. \n",
    "\n",
    "The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library. Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software.\n",
    "\n",
    "The data I used came from Live Piracy & Armed Robbery Report 2020. Reference: https://www.icc-ccs.org/index.php/piracy-reporting-centre/live-piracy-report\n",
    "\n",
    "![Home Page](images/home.png)\n",
    "\n",
    "## Main goal\n",
    "\n",
    "+ To access all of the content from the source code of the webpage with Python\n",
    "+ Parse and extract data. \n",
    "+ Save the info in CSV file for further analysis.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. Import Modules\n",
    "2. Get the URL link\n",
    "3. Navigate the URL Data Structure\n",
    "4. Testing out data requests\n",
    "5. Write data to a file in pseudo-code:\n",
    "    + Open up a file to write in and append data. \n",
    "    + Write headers\n",
    "    + Clear HTML tag and insert text in array\n",
    "    + Clear \\r \\n \\t to prepare string variable to clear Narrations: and insert text in array\n",
    "    + Prepare string variables Date, Time, Position, Area and Country, replace characters to insert character | and insert text in array\n",
    "    + Split to elements to array results for character | and Write to file items Date, Time, Position, Area and Country\n",
    "    + When complete, close the file\n",
    "6. The output file in CSV format.\n",
    "\n",
    "## Data info extracted:\n",
    "\n",
    "Date, Time, Position, Area and Country of Live Piracy & Armed Robbery Report 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![piracy reporting centre](images/piracy_reporting_centre.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have Beautiful Soup, install with 'conda install beautifulsoup' in terminal.\n",
    "\n",
    "Python requires us to explicitly load the libraries that we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have Beautiful Soup, install with 'conda install beautifulsoup' in terminal\n",
    "# Python requires us to explicitly load the libraries that we want to use:\n",
    "import requests\n",
    "import bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a webpage into python so that we can parse it and manipulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a webpage into python so that we can parse it and manipulate it.\n",
    "URL = 'https://www.icc-ccs.org/index.php/piracy-reporting-centre/live-piracy-report'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control of Connection. We just turned the website code into a Python object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control of Connection\n",
    "# We just turned the website code into a Python object. \n",
    "response = requests.get(URL)\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the tags with class narrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the tags with class narrations\n",
    "data = soup.findAll(attrs={'class':['jos_fabrik_icc_ccs_piracymap2016___narrations']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Source Code HTML](images/code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open new file, make sure path to your data file is correct.\n",
    "\n",
    "Later, I write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('piracy_reporting_centre.csv','w') # open new file, make sure path to your data file is correct\n",
    "f.write(\"Date\\tTime\\tPosition\\tArea\\tCountry\" + \"\\n\") # write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear HTML tag and insert text in array\n",
    "results = []                              # Initialize array results\n",
    "for element in data:                      # Iterate over the data array\n",
    "     TAG_RE = re.compile(r'<[^>]+>')      # Prepare pattern to clean html tag from str (element) strings\n",
    "     text = TAG_RE.sub('', str(element))  # Apply pattern and clean text html tag\n",
    "     results.append(text)                 # Insert text in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear \\r \\n \\t to prepare string variable to clear Narrations: and insert text in array\n",
    "results_explode = []      # Initialize results_explode array\n",
    "results_2 = []            # Inicializa arreglo results_2\n",
    "for element in results:   # Iterate over the results array of the previous cell\n",
    "     item = ''            # Initialize item\n",
    "     item = str(element)  # Assigns the value of item to each element of the results array\n",
    "     item = item.replace('\\r', '').replace('\\n', '').replace('\\t', '') # Replace item \\r, \\n, \\t to clean string and work better on it\n",
    "     if item != 'Narrations:':                 # Used to clean the Narrations: chain from the string:\n",
    "          results_explode = item.split(\".\")    # Perform explode for him. to keep the elements of the first line where they are Date, Time, Position, Area and Country and eliminate the paragraph that follows the line\n",
    "          i = 0                                # Initialize i\n",
    "          for result in results_explode:       # Iterate over the results_explode array\n",
    "                i = i + 1\n",
    "                if i <= 5: results_2.append(result) # Save the elements where they can later be extracted Date, Time, Position, Area and Country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare string variables Date, Time, Position, Area and Country, replace characters to insert character | and insert text in array\n",
    "i = 0                      # i\n",
    "results = []               # Initialize array results\n",
    "for element in results_2:  # Iterate over the results_2 array\n",
    "    i = i + 1\n",
    "    if i == 1: \n",
    "        data1 = str(element)  # Take element data1 to make up the date\n",
    "    if i == 2: \n",
    "        data2 = str(data1) + '.' + str(element) # Take element data1 and concatenate str (element) to make up the date\n",
    "    if i == 3: \n",
    "        date = data2 + '.' + str(element) # take date element plus other strings and concatenate str (element) to make up the date\n",
    "    if i == 4: \n",
    "        position = str(element)    # Take element position plus other strings\n",
    "    if i == 5: \n",
    "        country = str(element)     # Take country element plus other strings\n",
    "        item = date.replace(': Posn : ', '|').replace(': Posn: ', '|').replace(': ', '|') + '.' + position.replace(' – ', '|') + '.' + country.replace('E, ', 'E|').replace('W, ', 'W|')\n",
    "        item = item.replace('N – ', 'N|').replace('W, ', 'W|') # Performs replacement of : Posn : for |, : Posn: for |, : for |,  –  for |, E, for E|, W, for W| to form a line where the elements are well delimited Date, Time, Position, Area and Country by the separator |  \n",
    "        results.append(item)    # Adiciona la linea donde estan bien delimitados los elemento Date, Time, Position, Area and Country por el separador | al arreglo results\n",
    "        i = 0                   # Pone  en 0 para poder tomar los sgtes 5 elementos del arreglos results_2 donde estan los elementos utiles a extraer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to elements to array results for character | and Write to file items Date, Time, Position, Area and Country\n",
    "for element in results:\n",
    "       item = element.split(\"|\") # Realiza explode por el caracter | para quedarnos con los elementos Date, Time, Position, Area and Country\n",
    "       i = 0\n",
    "       for element1 in item:\n",
    "            i = i + 1\n",
    "            if i == 1: \n",
    "                date = str(element1)\n",
    "                f.write(date + \"\\t\") # fecha date and add tabulator\n",
    "            if i == 2: \n",
    "                time = str(element1)\n",
    "                f.write(time + \"\\t\") # fecha time and add tabulator\n",
    "            if i == 3: \n",
    "                position = str(element1)\n",
    "                f.write(position + \"\\t\") # fecha position and add tabulator\n",
    "            if i == 4: \n",
    "                area = str(element1)\n",
    "                f.write(area + \"\\t\") # fecha area and add tabulator\n",
    "            if i == 5: \n",
    "                country = str(element1)\n",
    "                f.write(country + \"\\t\\n\") # fecha country and add tabulator                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close file\n",
    "f.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cvs data](images/cvs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "We used Beautiful Soup as the main tool. The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library.\n",
    "\n",
    " Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
